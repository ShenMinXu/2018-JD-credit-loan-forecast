{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python3.5\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator, ZeroCount\n",
    "import math\n",
    "import os  \n",
    "mingw_path = 'D:\\MINGW\\mingw64\\bin'  \n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH'] \n",
    "import xgboost as xgb \n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def deletezero(x):\n",
    "    if x<3.8:\n",
    "        result = 0\n",
    "    else:\n",
    "        result = x\n",
    "    return result\n",
    " \n",
    "read_x1 = pd.read_csv('D:/研究生/Chaos/JD/信贷需求/traindata/traindata.csv')\n",
    "read_y1 = pd.read_csv('D:/研究生/Chaos/JD/信贷需求/traindata/traindata_label.csv')\n",
    "read_x2 = pd.read_csv('D:/研究生/Chaos/JD/信贷需求/testdata/testdata.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-error:0.2\ttrain-error:0.141092\n",
      "[1]\teval-error:0.2\ttrain-error:0.13963\n",
      "[2]\teval-error:0.2\ttrain-error:0.140356\n",
      "[3]\teval-error:0.2\ttrain-error:0.139707\n",
      "[4]\teval-error:0.2\ttrain-error:0.13907\n",
      "[5]\teval-error:0.2\ttrain-error:0.138575\n",
      "[6]\teval-error:0.2\ttrain-error:0.138334\n",
      "[7]\teval-error:0.2\ttrain-error:0.137894\n",
      "[8]\teval-error:0.2\ttrain-error:0.13741\n",
      "[9]\teval-error:0.2\ttrain-error:0.137289\n",
      "[10]\teval-error:0.2\ttrain-error:0.137399\n",
      "[11]\teval-error:0.2\ttrain-error:0.137234\n",
      "[12]\teval-error:0.2\ttrain-error:0.137136\n",
      "[13]\teval-error:0.2\ttrain-error:0.136905\n",
      "[14]\teval-error:0.2\ttrain-error:0.136784\n",
      "[15]\teval-error:0.2\ttrain-error:0.136553\n",
      "[16]\teval-error:0.2\ttrain-error:0.136542\n",
      "[17]\teval-error:0.2\ttrain-error:0.136344\n",
      "[18]\teval-error:0.2\ttrain-error:0.136278\n",
      "[19]\teval-error:0.2\ttrain-error:0.136289\n",
      "[20]\teval-error:0.2\ttrain-error:0.1363\n",
      "[21]\teval-error:0.2\ttrain-error:0.136168\n",
      "[22]\teval-error:0.2\ttrain-error:0.136146\n",
      "[23]\teval-error:0.2\ttrain-error:0.136003\n",
      "[24]\teval-error:0.2\ttrain-error:0.135883\n",
      "[25]\teval-error:0.2\ttrain-error:0.135663\n",
      "[26]\teval-error:0.2\ttrain-error:0.135784\n",
      "[27]\teval-error:0.2\ttrain-error:0.135443\n",
      "[28]\teval-error:0.2\ttrain-error:0.135465\n",
      "[29]\teval-error:0.2\ttrain-error:0.135421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python3.5\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# x1 = read_x1[['loan_8_sum','loan_9_sum','loan_10_sum','loan_8_mean','loan_9_mean','loan_10_mean',\\\n",
    "#               'loan_price_sum','topay_thismonth','topay_thismonth1','repayment_ability','last_loan_amount',\\\n",
    "#               'click_count_sum','order_count_sum','click_model']] \n",
    "x1 = read_x1\n",
    "y1 = read_y1\n",
    "y1['loan_11_sum'] = y1.loan_11_sum.apply(lambda x:1 if x>0 else 0)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(x1,y1, test_size=0.0001,random_state=0)  \n",
    "\n",
    "\n",
    "\n",
    "dataset1 = xgb.DMatrix(train_x,label=train_y)\n",
    "dataset_valid = xgb.DMatrix(valid_x,label=valid_y)\n",
    "param = {  \n",
    "         'eta':0.1,\n",
    "         'subsample':0.7,\n",
    "         'objective':'binary:logistic' }    \n",
    "evallist  = [(dataset_valid,'eval'), (dataset1,'train')]   \n",
    "#evallist  = [(dataset1,'train')] \n",
    "num_round = 30\n",
    "bst = xgb.train(param, dataset1, num_round,evallist ) \n",
    "\n",
    "\n",
    "# x2 = read_x2[['uid','loan_8_sum','loan_9_sum','loan_10_sum','loan_8_mean','loan_9_mean','loan_10_mean',\\\n",
    "#               'loan_price_sum','topay_thismonth','topay_thismonth1','repayment_ability','last_loan_amount',\\\n",
    "#               'click_count_sum','order_count_sum','click_model']] \n",
    "x2 = read_x2\n",
    "dataset3_preds = x2[['uid']]\n",
    "x2.drop('uid',axis=1,inplace=True)\n",
    "dataset3 = xgb.DMatrix(x2)\n",
    "dataset3_preds['class'] = bst.predict(dataset3)\n",
    "dataset3_preds.to_csv(\"my_xgb_class.csv\",index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save feature score\n",
    "feature_score = bst.get_fscore()\n",
    "feature_score = sorted(feature_score.items(), key=lambda x:x[1],reverse=True)\n",
    "fs = []\n",
    "for (key,value) in feature_score:\n",
    "    fs.append(\"{0},{1}\\n\".format(key,value))\n",
    "    \n",
    "with open('xgb_classify_feature_score.csv','w') as f:\n",
    "    f.writelines(\"feature,score\\n\")\n",
    "    f.writelines(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [loan_11_sum]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "t = valid_y[valid_y.loan_11_sum<0]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
